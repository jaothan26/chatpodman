# Default values for chatpodman
replicaCount: 2

image:
  repository: localhost/llama-model-service
  pullPolicy: IfNotPresent
  tag: "latest"

service:
  type: LoadBalancer
  port: 8000

resources:
  limits:
    cpu: 4
    memory: 16Gi
    nvidia.com/gpu: 1

redis:
  enabled: true
